This note describes how the operation system will work and
how the back testing works.

* operation system

The models will be deployed in some type of to-be-specified streaming
framework. The initial stream will consist of all of the trace
prints. This stream will be broken into a separate stream for each
ticker.

Each ticker-specific stream will be fed into its own process. The
process takes in a trace print for a ticker and accumulates
trace-print information for the cusips related to the ticker. It
produces an output stream containing trace-print features for each
individual cusip. The features generated by this process include:
- the current oasspread, quantity, and price
- the estimated dealer order imbalance
- for the last K trades for each trade type, their weighted average
  oasspread, quantity, price, and mean-time between trades
- features from the curent on-the-run cusip. The identity of this
  cusip will vary from trace print to trace print.

The trace-print cusip-specific feature stream will be fed into a
process that augments the trace-print features with features of the
ticker and cusip. All of these features will be time dependent with
various windows time cycles. Some second-by-second, for example,
whether there has been significant news for the ticker. Some will
change daily, such as the cusip's days to maturity. Some will not
change at all during the life of the ticker and cusip, such as the
ticker's SIC code and the cusip's coupon type.

The augmented feature stream is fed into a process that splits it into
a separate stream for each trade type. Note that the trade-type
feature stream contains information from all the trade types. The
trade-type stream is fed into two downstream process: the model
fitting process and the prediction process.

Each trade-type feature stream is fed into a model fitting process. In
the initial deployment, this process runs periodically, say every five
minutes. Later we can decide whether to retrain with every trace
print. When it runs, it sweeps a set of hyperparameters to detemine
the best models right now. It produces a fitted model for every target
variable that we predict. The fitted model is probably an ensemble of
the best models. There is one model for each combination of cusip,
trade-type, target variable (oas spread, holding period, etc), and
hyper-parameter setting.

Each trade-type feature stream is fed into a process that makes
predictions. This process also reads the input stream that contains
the fitted models for the trade type and target feature. The
predictions are fed into another process that makes decisions. The
predictions will be made by using a fitted model that takes a
trade-type feature vector and produces the estimates. The latest
feature vector for the cusip and trade type will be used as input
to the fitted model. The fitted model will produce the target variable,
which for now, is the oasspread for the next trade of the trade type.
Later we will predict the time to the next trade of the trade type.

The decision process takes all of the prediction stream as
inputs. Thus it sees every prediction for every cusip for every trade
type across tickers.  The initial version might observe just the
predictions for a specific ticker.  The decision process
decides which trades to execute and sends those decisions to a
downstream trade execution process. The results of those executions
are fed back into the collections of streams as trace prints and as
execution reports.

The trade execution process reads the trade orders, executes them, and 
creates a stream of execution reports.

The execution reports stream and the prediction stream are fed
into a measurement process that determines the current accuracy of the
predictions. Probably a person monitors the accuracy and can kill
the execution engine interactively. There will probably also be
automated execution-killing mechanisms.

(Note: a diagram should be provided to explain the flows.)

* Back-fitting program design

Our program fit_predict3.py simulates portions of the operational
environment in order to assess the accuracy of the models and
associated hyperparameter settings and to determine which features are
most important for the most accurate models.

This program is invoked with these invocation parameters:
- the ticker, for example ORCL.
- the cusip, for example 68389XAS4 (which is an ORCL cusip)
- the name of the hyperparameter set to search over, for example grid2
- the effective date for the trace prints the program is to estimate,
  for example 2016-11-01. The effective date is an input parameter
  so that multiple instances of the program can be run in parallel,
  reducing the wall clock time needed to train all the models.

The output of the program is two files.
- file predictions.csv contains the predictions and actual oasspread
  identified by the trace print, the hyperparameters, and the trade
  type.  The hyperparameters include the type of the model (naive,
  elastic net, and random forests so far).
- file importances.csv contains the importance of each feature
  identified by the trace print, the hyperparameters, and the trade
  type. The importances is a number between 0 and 1, where higher
  means more importance. Exactly what importance means depends on the
  type of the model and is not consistent across models.

The module feature_maker.py contains classes that create the feature
set by simulating the presentation of trace print records one by
one. The logic in class AllFeatures accepts a new trace print record
and produces a Pandas DataFrame containing the features. The class is
instantiated for a specific cusip. The trace prints that are fed to it
are the trace prints for the primay cusip and the trace prints for all
on-the-run cusips related to the primary cusip.

The fit_predict3.py works by issuer. The an issuer, it groups
the cusips based on similar maturity date and other features. For
each cusip c, define on-the-run(c) to be the on-the-run sibling in the
group.

To predict the oas spread at time t of a trace print, use information
about the cusip c and on-the-run(c) before t. This information
includes information on the issue, the cusip, the trade itself (for
example, the quantity traded), and a summary of the prior trades.

* secret portion (not in final document)

Here is the algorithm for fit_predict3.py.
1. Read the trace prints. Sort them into increasing effective datetime
   order. Drop all trace_prints except for the specified CUSIP and the
   on-the-run CUSIPs related to it.
2. Read the files containing information on the ticker and cusip. This
   information is needed to augment the trace print information with
   features from the ticker and cusip. These files are lazily-read
   by the feature_maker.py module.
3. Process each trace print for the cusip and related on-the-run
   cusips in order of increasing effective datetime.
   + Create features from the trace print. Some of the features are
     derived from previous trace prints. For example, one feature is
     the oasspread of the previous trade. Features from all trade type
     are used to create the feature, so that if the trace print is for
     a D trace, the features for the trace print contain recent
     information from S and D trades and well as recent information
     from D trades. In addition to the features, some identifying
     information is captured, including the trace print identifier and
     the effective datetime.
   + Create the targets from the trace prints. We predict several
     target values, all of which are stored in one file for
     convenience. One set of targets is around the oas spreads.  These
     targets are stored in 3 fields: target_oasspread_B,
     target_oasspread_D, and target_oasspread_S, depending on the
     trade type. Another target will be based on the elapsed time
     since the last trade. Two values are stored:
     target_seconds_from_last_trade,
     target_seconds_from_last_trade_of_same_tradetype.  In addition to
     the targets, some identifying information is captured, including
     the trade print identifier.
   + Accumulate the features and targets into two parallel
     arrays. This is done in the function do_work().
   + For each trade type and model spec:
     - Fit a model. The training date are all the feature
       and targets including the most recent trace print.  
     - Predict the oasspread for the most recent trace print. The 
       query vector is the features of the most recent trade.
     - Write csv files containing the predictions and importances of
       the features.














